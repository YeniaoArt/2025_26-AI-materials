{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKYj9A4wkLpX"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This worksheet covers linear regression. Similar to last week, you will do some work implementing your own versions of these algorithms, to ensure that you understand the details of them. You will also compare them with the implementations in scikit-learn to test your implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5r8OdA2kLpc"
   },
   "source": [
    "The box plots show that there is no clear difference in performance between the two models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELQXS6wLkLpc"
   },
   "source": [
    "## Linear Regression\n",
    "In linear regression we make the assumption that the data $(x_i, y_i)$ can be modelled by a function of the form\n",
    "$$ \\hat{y_i} = f(\\vec{x}_i)= \\sum_j a_j x_{ij}  + b_i$$\n",
    "\n",
    "Recall that we can express this in a matrix format by:\n",
    "$$ \\hat{\\vec{y}} = f(X)= X\\Theta$$\n",
    "\n",
    "where\n",
    "$$ X=\\begin{pmatrix}\n",
    "x_{1,1} & x_{1,2} & \\ldots & x_{1,n} &1 \\\\\n",
    "\\vdots & \\vdots & \\ldots & \\vdots & \\vdots \\\\\n",
    "x_{N,1} & x_{N,2} & \\ldots & x_{N,n} & 1\n",
    "\\end{pmatrix}, \\quad \\vec{y}=\\begin{pmatrix} y_1 \\\\ \\vdots \\\\y_N \\end{pmatrix}, \\quad \\Theta=\\begin{pmatrix} a_1 \\\\ \\vdots \\\\a_n\\\\b \\end{pmatrix}$$\n",
    "\n",
    "We saw in lectures that the optimal value of $\\Theta$ is given by setting\n",
    "$$ \\Theta = (X^T X)^{-1} X^T \\vec{y}$$\n",
    "\n",
    "The quantity $(X^T X)^{-1} X^T$ is called the psuedoinverse of X, and can be computed using the function `np.linalg.pinv`.\n",
    "\n",
    "We will (a) perform a linear regression on the diabetes dataset. You can load this dataset using the function `load_diabetes` from `sklearn.datasets`. (b) compute the mean squared error and the R^2, and (c) compare your results with the built in function in sklearn (`sklearn.linear_model.LinearRegresion()`). You should get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LHZ3wibkLpc"
   },
   "outputs": [],
   "source": [
    "# import statments here\n",
    "import math\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WauUANOlkLpc"
   },
   "source": [
    "## Part (a) Implementing linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mP-K0HLokLpd"
   },
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "Y = diabetes.target\n",
    "\n",
    "# Split the dataset into training, validation and test, using test_size=0.2\n",
    "Xtr, Xtest, Ytr, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xtr, Ytr, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pBEWQQokLpd"
   },
   "outputs": [],
   "source": [
    "# Add a column of ones to your Xtrain and Xtest for the intercept term\n",
    "Wtrain=np.hstack([Xtrain, np.ones((len(Xtrain),1))])\n",
    "Wval=np.hstack([Xval, np.ones((len(Xval),1))])\n",
    "Wtest=np.hstack([Xtest, np.ones((len(Xtest),1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huAU6k-GkLpd"
   },
   "outputs": [],
   "source": [
    "# Calculate the value of the coefficients theta. You can use the function np.linalg.pinv\n",
    "theta = np.linalg.pinv(Wtrain).dot(Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87EPT61CkLpd"
   },
   "source": [
    "## Part (b) Computing performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nG5XaCZIkLpd"
   },
   "outputs": [],
   "source": [
    "# Make a prediction on the test set by applying the coefficients theta to the test set\n",
    "my_pred = Wval.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPOgP8VgkLpd"
   },
   "outputs": [],
   "source": [
    "# Calculate the mean squared error and the R^2.\n",
    "# You can use the built in functions from sklearn\n",
    "print(f'mean squared error= {mean_squared_error(my_pred, Yval):.4f}')\n",
    "print(f'R^2={r2_score(my_pred, Yval):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWB85HU7kLpd"
   },
   "source": [
    "## Part (c) Checking results\n",
    "Compare your results with the built in function `sklearn.linear_model.LinearRegression()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqB82hnhkLpd"
   },
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaTvf2fCkLpd"
   },
   "outputs": [],
   "source": [
    "regr.fit(Xtrain, Ytrain)\n",
    "pred = regr.predict(Xval)\n",
    "print(f'mean squared error= {mean_squared_error(pred, Yval):.4f}')\n",
    "print(f'R^2={r2_score(pred, Yval):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCvWR5ZukLpd"
   },
   "source": [
    "Visualise the perfomance of the regression by plotting your predicted values vs target values on a scatter plot, and drawing a line y=x. If all predictions were perfect, the predicted values would lie on the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yn2_-FfRkLpd"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.ylim(20, 350)\n",
    "plt.xlim(20, 350)\n",
    "plt.scatter(pred,Yval,color='black')\n",
    "x = np.linspace(20,350,100)\n",
    "y=x\n",
    "plt.plot(x, y,color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOT92TMkLpd"
   },
   "source": [
    "# Extra question: Polynomial regression\n",
    "The term 'linear' in linear regression refers only to the coefficients $\\theta$. We can in fact compute polynomial terms in the data and perform linear regression over this extended dataset to get a better fit to the data.\n",
    "\n",
    "To compute polynomial terms in the data automatically, you can use the class `sklearn.preprocessing.PolynomialFeatures`. To find out how to use it, look at the guidance (you can type `help(PolynomialFeatures)` once you have imported it).\n",
    "\n",
    "The following small dataset (in the cell below) gives a relationship between temperature and yield for an experiment. Use cross-validation to select the degree of the polynomial that best fits this data.\n",
    "\n",
    "Plot the mean squared error against degree on the training set and on the validation set. Which degree of polynomial best fits this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBDRO8XNkLpd"
   },
   "outputs": [],
   "source": [
    "X = np.array([50,50,50,70,70,70,80,80,80,90,90,90,100,100,100]).reshape(-1, 1)\n",
    "y = np.array([3.3,2.8,2.9,2.3,2.6,2.1,2.5,2.9,2.4,3,3.1,2.8,3.3,3.5,3]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNWKuuW2kLpd"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "Xtr, Xtest, Ytr, Ytest = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xtr, Ytr, test_size=0.2, random_state=0)\n",
    "mse_tr = []\n",
    "mse_val = []\n",
    "max_deg = 10\n",
    "for i in range(max_deg):\n",
    "    poly=PolynomialFeatures(degree=i+1)\n",
    "    Xtrain_new = poly.fit_transform(Xtrain)\n",
    "    Xval_new = poly.fit_transform(Xval)\n",
    "    regr.fit(Xtrain_new, Ytrain)\n",
    "    pred_tr = regr.predict(Xtrain_new)\n",
    "    pred_v = regr.predict(Xval_new)\n",
    "    mse_tr.append(mean_squared_error(pred_tr, Ytrain))\n",
    "    mse_val.append(mean_squared_error(pred_v, Yval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QI9D5GvDkLpd"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, max_deg+1), mse_tr, label='Training')\n",
    "plt.plot(range(1, max_deg+1), mse_val, label='Validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsY6qJawkLpd"
   },
   "outputs": [],
   "source": [
    "Xtest_new = poly.fit_transform(Xtest)\n",
    "pred_test = regr.predict(Xtest_new)\n",
    "mean_squared_error(pred_test, Ytest)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc4778dd1211f1bf59455cd46029fa692529fbc0d32c0ba0949d8ddd432c76af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
